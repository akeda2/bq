#!/bin/bash

# simple task queue; output files are in /dev/shm/bq-$USER.  Uses no locks;
# use 'mv' command, which is atomic (within the same file system anyway) to
# prevent contention.
# ref: https://rcrowley.org/2010/01/06/things-unix-can-do-atomically.html

# run "bq -w" once to start a worker

# run "bq command [args...]" to put commands in queue

# run "bq" to view the output directory using ranger

# see README for more (e.g., using different queues, increasing/decreasing the
# number of workers in a queue, etc.)

# ----------------------------------------------------------------------

die() { echo "$@" >&2; exit 1; }

[ "$1" = "-h" ] && {
    cat <<-EOF
	Example usage:
	    # start a worker
	    bq -w
	    # submit a job
	    bq some-command arg1 arg2 [...]
	    # check status
	    bq                              # uses ranger as the file manager
	    export BQ_FILEMANAGER=mc; bq    # env var overrides default
	    # you can only run one simple command; if you have a command with
	    # shell meta characters (;, &, &&, ||, >, <, etc), do this:
	    bq bash -c 'echo hello; echo there >junk.\$RANDOM'
	EOF
    exit 1
}

# ----------------------------------------------------------------------
# SETUP

TMP=/dev/shm
[ -d $TMP ] || TMP=/tmp

# I doubt I will ever use multiple Qs, but it's easy enough to implement
Q=default
[ "$1" = "-q" ] && {
    [ -z "$2" ] && die "-q needs a queue name"
    Q=$2; shift; shift
}
[ -z "$QDIR" ] && export QDIR=$TMP/bq-$USER-$Q
mkdir -p $QDIR/w
mkdir -p $QDIR/q
mkdir -p $QDIR/OK

_exit=0     # as long as this is 0, the main loop will keep running

# ----------------------------------------------------------------------
# WORK 1 TASK

_work_1() {
    ID=$1

    # "claim" the task in q by renaming q/$ID to a name that contains our
    # own PID.  Unix mv is atomic within the same filesystem, so this
    # prevents contention among multiple workers.
    mv q/$ID $ID.running.$$

    # if the "claim" succeeded, we got the task
    if [ -f $ID.running.$$ ]
    then
        # get the command line arguments and run them
        readarray -t cmd < $ID.running.$$

        # the first line is the directory to be in; shift that out first
        newpwd="${cmd[0]}"
        cmd=("${cmd[@]:1}")

        # handle "exit"
        if [ "${cmd[0]}" = "exit" ]
        then
            rm $ID.running.$$
            _exit=1     # signal the main loop we're done
            return
        fi

        # log the command for debugging later
        echo -n "cd $newpwd; ${cmd[@]}" >> w/$$

        # the directory may have disappeared between submitting the
        # job and running it now.  Catch that by trying to cd to it
        cd "$newpwd" || cmd=(cd "$newpwd")
        # if the cd failed, we simply replace the actual command with
        # the same "cd", and let it run and catch the error.  Bit of a
        # subterfuge, actually, but it works fine.

        # finally we run the task.  Note that our PWD now is NOT $QDIR, so
        # the two redirected filenames have to be fully qualified
        "${cmd[@]}" > $QDIR/$ID.1 2> $QDIR/$ID.2
        ec=$?

        cd $QDIR
        mv $ID.running.$$ $ID.exitcode=$ec
        [ "$ec" = "0" ] && mv $ID.* OK
        echo " # $ec" >> w/$$
    fi
}

# ----------------------------------------------------------------------
# START AND DAEMONISE A WORKER

# '-w' starts a worker; each worker runs one job at a time, so if you want
# more jobs to run simultaneously, run this multiple times!
[ "$1" = "-w" ] && [ -z "$2" ] && {
    # daemonize
    nohup "$0" -w $QDIR &

    # remind the user how many workers he has started, in case he forgot
    sleep 0.5   # wait for the other task to kick off
    echo `cd $QDIR/w; ls | grep -v exited | wc -l` workers running
    exit 0
}

# ----------------------------------------------------------------------
# WORKER LOOP

[ "$1" = "-w" ] && {

    touch $QDIR/w/$$
    trap "mv $QDIR/w/$$ $QDIR/w/$$.exited" 0

    while [ "$_exit" = "0" ]
    do
        cd $QDIR

        # if nothing is waiting in q, go to sleep, but using inotifywait so
        # you get woken up immediately if a new task lands
        [ -z "`cd q; ls`" ] && inotifywait -t 60 -e create q >/dev/null
        # note there is still a bit of a race here.  If tasks were submitted
        # *between* the 2 pieces of the above code, they will end up waiting
        # 60 seconds before they get picked up.  Hopefully that's a corner
        # case, and anyway at worst it only causes a delay.

        # pick up all tasks in q and run them.  Note that there may not be any
        # (the inotifywait may have exited on timeout rather than on a create
        # event) but that's fine too
        for ID in $(cd q; ls)
        do
            _work_1 $ID
        done
    done

    exit 0
}

# ----------------------------------------------------------------------
# STATUS

# examine the output directory using $BQ_FILEMANAGER (defaulting to ranger)
[ -z "$1" ] && exec sh -c "${BQ_FILEMANAGER:-ranger} $QDIR"

# ----------------------------------------------------------------------

# some command was given; add it to the queue
ID=`date +%s`.$$.${1//[^a-z0-9_.-]/}
pwd                 > $QDIR/q/$ID
printf "%s\n" "$@" >> $QDIR/q/$ID
